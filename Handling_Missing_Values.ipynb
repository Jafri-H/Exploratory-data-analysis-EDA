{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qerwJaWtVnW0"
      },
      "source": [
        "#### Methods to Handle Missing Values:\n",
        "1. **Imputation** - using statistical values to fill missing values\n",
        "2. **Dropping** - dropping the missing value rows"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In ML or Data Science , we use datasets which are use to train our ML models.\n",
        "* Once the ML is trained with the dataset, we can make new predictions.\n",
        "* In order to feed the dataset into the ML, we need to clean the data."
      ],
      "metadata": {
        "id": "WLyZzkTaD1lK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESeG8Bc0Ytcz"
      },
      "source": [
        "#### Importing the libraries\n",
        "\n",
        "*  Pandas for making pandas dataframe which is nothing but structured table.\n",
        "*  Matplotlib for visuals\n",
        "*  Seaborn for plot and graph\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G73e8tnFVi3z"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the dataset to a Pandas DataFrame:"
      ],
      "metadata": {
        "id": "lNcfbeHvGQEE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCANYhqVY6Pm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "062f7864-a41b-4534-98ea-433b89e6a6af"
      },
      "source": [
        "dataset = pd.read_csv('/content/Placement_Dataset.csv')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Placement_Dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-85189cd195d3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Placement_Dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Placement_Dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking the first 5 rows of the dataset"
      ],
      "metadata": {
        "id": "dxhkTE96H0Px"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOSLBTzkZMlI"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Columns Description:\n",
        "- **sl_no**: Serial Number  \n",
        "- **gender**: Gender  \n",
        "- **ssc_p**: Secondary School Certificate Percentage (or 10th Grade Percentage)  \n",
        "- **ssc_b**: Secondary School Certificate Board (or 10th Grade Board)  \n",
        "- **hsc_p**: Higher Secondary Certificate Percentage (or 12th Grade Percentage)  \n",
        "- **hsc_b**: Higher Secondary Certificate Board (or 12th Grade Board)  \n",
        "- **hsc_s**: Higher Secondary Certificate Stream (or 12th Grade Stream, e.g., Science, Commerce, Arts)  \n",
        "- **degree_p**: Degree Percentage (or Undergraduate Percentage)  \n",
        "- **degree_t**: Degree Type (or Undergraduate Degree Type, e.g., B.Tech, B.Com, B.Sc)  \n",
        "- **workex**: Work Experience (whether the candidate has prior work experience)  \n",
        "- **etest_p**: Employability Test Percentage (or Entrance Test Percentage)  \n",
        "- **specialisation**: Specialisation (e.g., MBA specialisation like Marketing, Finance)  \n",
        "- **mba_p**: MBA Percentage (or Postgraduate Percentage)  \n",
        "- **status**: Placement Status (whether the candidate is placed or not)  \n",
        "- **salary**: Salary (offered to the candidate, if placed)  "
      ],
      "metadata": {
        "id": "S6OcYG7aGzVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finding the rows and columns in the dataset"
      ],
      "metadata": {
        "id": "To77zouGHi8i"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAbAvqhyZQZU"
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finding the missing values in each column"
      ],
      "metadata": {
        "id": "yK90J7ABHq9M"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_kZfcSuZj6S"
      },
      "source": [
        "dataset.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* There are 67 missing values in salary column."
      ],
      "metadata": {
        "id": "iT23FyUtH7t9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOlWuDtbZ62m"
      },
      "source": [
        "#### Central Tendencies:\n",
        "1. **Mean**: Average of all the values.\n",
        "2. **Median**: Middle value.\n",
        "3. **Mode**:Most repeated value."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Analyzing the **symmetry** of the dataset to determine which measure of central tendency to use for filling missing values."
      ],
      "metadata": {
        "id": "0KPsnnAXI644"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "sns.histplot(dataset.salary)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cueF_4wKKFXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Mostly the value around 250 thousand.\n",
        "* The data is Right skewed.\n",
        "   * Right-skewed (positive skewness) → Tail is longer on the right.\n",
        "   * Left-skewed (negative skewness) → Tail is longer on the left.\n",
        "   * Symmetric (normal distribution) → Balanced on both sides.\n",
        "* We have outliers in the data so we can not use mean value.\n",
        "* For skew distribution we either use median or mode.\n",
        "\n"
      ],
      "metadata": {
        "id": "U4s8X0gAKlts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imputation Method:"
      ],
      "metadata": {
        "id": "7pF_MwJsMsAi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6msZoE3bYkE"
      },
      "source": [
        "#### Replace the missing values with Median value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrPReLx8a6Wn"
      },
      "source": [
        "dataset['salary'] = dataset['salary'].fillna(dataset['salary'].median())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking Missing value:"
      ],
      "metadata": {
        "id": "bncGngNiMf0V"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJD7xzWMbumd"
      },
      "source": [
        "dataset.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* All the missing values of salary column has been filled with median value."
      ],
      "metadata": {
        "id": "jycl4Mq9MWhP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdoDwU8wcXZX"
      },
      "source": [
        "### Dropping Method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP-llMUscL5S"
      },
      "source": [
        "salary_dataset = pd.read_csv('/content/Placement_Dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9qDpkUKchNR"
      },
      "source": [
        "salary_dataset.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETZJ_G7sckYk"
      },
      "source": [
        "salary_dataset.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dropping the missing values:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ytI_CSMhNFrI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5CR8ARGcoGc"
      },
      "source": [
        "salary_dataset = salary_dataset.dropna(how = 'any')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iepl2NSCc1H7"
      },
      "source": [
        "salary_dataset.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed5_C3nYc3Km"
      },
      "source": [
        "salary_dataset.shape"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}